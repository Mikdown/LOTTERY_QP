{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mikdown/Lottery-Picker/blob/master/colab_lotto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ciAogFP5eKQJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', 20)\n",
        "pd.set_option('display.width', 1000)\n",
        "import numpy as np\n",
        "import datetime\n",
        "import random\n",
        "import sqlite3\n",
        "from collections import Counter\n",
        "mega_draw_file_url = (\"https://raw.githubusercontent.com/Mikdown/Lottery-Picker/master/assets/megamillions.csv\")\n",
        "mega_weather_file_url = (\"https://raw.githubusercontent.com/Mikdown/Lottery-Picker/master/assets/mega_weather.csv\")\n",
        "pb_draw_file_url = (\"https://raw.githubusercontent.com/Mikdown/Lottery-Picker/master/assets/powerball.csv\")\n",
        "pb_weather_file_url = (\"https://raw.githubusercontent.com/Mikdown/Lottery-Picker/master/assets/pb_weather.csv\")\n",
        "\n",
        "conn = sqlite3.connect('lottery_data.db')\n",
        "\n",
        "cur = conn.cursor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO-6wKUjeKQK"
      },
      "source": [
        "###The following four code cells meet the first and second feature requirements:\n",
        "1. Feature 1. Read two data files (CSV).\n",
        "2. Feature 2. Clean your data.\n",
        "    - Four CSV files are read in from Github and cleaned(transformed) with Pandas. \n",
        "3. Feature 1. Set up a local database and read data in with SQLite.\n",
        "4. Feature 2. Perform a SQL join.\n",
        "    - After transformation the files are read into a local SQLite3 DB to be used for futher analysis.\n",
        "    - Data is read in from the database, filtered, grouped and a SQL join is performed on 2 tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c7347cf-6f65-4c28-c0af-3c7e91a42051",
        "id": "Dhjb2ff4DT_D"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Date           game  num_1  num_2  num_3  num_4  num_5  mb     month day_name  day_num  day_date draw_time\n",
            "0    2003-12-05  Mega Millions     12     44     15     18      1  42  December   Friday        4         5      2300\n",
            "1    2003-12-09  Mega Millions     14     15     48      4     24  41  December  Tuesday        1         9      2300\n",
            "2    2003-12-12  Mega Millions     16     32     46      9     45  26  December   Friday        4        12      2300\n",
            "3    2003-12-16  Mega Millions     47     16     31     24     46  47  December  Tuesday        1        16      2300\n",
            "4    2003-12-19  Mega Millions      5     10     39     17     35  38  December   Friday        4        19      2300\n",
            "...         ...            ...    ...    ...    ...    ...    ...  ..       ...      ...      ...       ...       ...\n",
            "2006 2023-02-24  Mega Millions     22     49      2     65     67   7  February   Friday        4        24      2300\n",
            "2007 2023-02-28  Mega Millions     59     52     40     14     16  13  February  Tuesday        1        28      2300\n",
            "2008 2023-03-03  Mega Millions     39      8     67     36     25  11     March   Friday        4         3      2300\n",
            "2009 2023-03-07  Mega Millions     15     69     28     25     22  21     March  Tuesday        1         7      2300\n",
            "2010 2023-03-10  Mega Millions     60      9     20     59     63   5     March   Friday        4        10      2300\n",
            "\n",
            "[2011 rows x 13 columns]\n",
            "                 DATE_TIME DPTemp  DBTemp  Precip  RHumid       Date  Time\n",
            "0      2013-01-01 00:53:00     36      47     0.0      66 2013-01-01  0053\n",
            "1      2013-01-01 01:53:00     36      43     0.0      76 2013-01-01  0153\n",
            "2      2013-01-01 02:51:00     37      45     0.0      76 2013-01-01  0251\n",
            "3      2013-01-01 02:53:00     37      44     0.0      76 2013-01-01  0253\n",
            "4      2013-01-01 03:53:00     38      45     0.0      77 2013-01-01  0353\n",
            "...                    ...    ...     ...     ...     ...        ...   ...\n",
            "115441 2022-12-16 22:53:00     28      43     0.0      56 2022-12-16  2253\n",
            "115442 2022-12-16 23:53:00     27      44     0.0      51 2022-12-16  2353\n",
            "115443 2022-12-16 23:59:00    NaN       0     0.0       0 2022-12-16  2359\n",
            "115444 2022-12-17 00:53:00     28      45     0.0      52 2022-12-17  0053\n",
            "115445 2022-12-17 01:53:00     28      45     0.0      52 2022-12-17  0153\n",
            "\n",
            "[115446 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "mega_draw_file = (mega_draw_file_url)\n",
        "mega_weather_file = (mega_weather_file_url)\n",
        "\n",
        "mega_draw_df = pd.read_csv(mega_draw_file, engine='python', parse_dates= {\"draw_date\" : [\"year\",\"month\",\"day\"]})\n",
        "mega_weather_df = pd.read_csv(mega_weather_file, engine='python')\n",
        "\n",
        "#Split the \"DATE_TIME\" column into 2 seperate columns \"Date\" and \"Time\".\n",
        "\n",
        "mega_weather_df['Date'] = pd.to_datetime(mega_weather_df['DATE_TIME']).dt.strftime('%Y%m%d')\n",
        "mega_weather_df['Time'] = pd.to_datetime(mega_weather_df['DATE_TIME']).dt.strftime('%H%M')\n",
        "\n",
        "mega_weather_df['Date'] = pd.to_datetime(mega_weather_df['Date'])\n",
        "mega_weather_df['DATE_TIME'] = pd.to_datetime(mega_weather_df['DATE_TIME'])\n",
        "\n",
        "mega_draw_df.rename({'draw_date': 'Date'}, axis=1, inplace=True)\n",
        "mega_draw_df['Date'] = pd.to_datetime(mega_draw_df['Date']).dt.strftime('%Y%m%d')\n",
        "mega_draw_df['Date'] = pd.to_datetime(mega_draw_df['Date'])\n",
        "mega_draw_df['month'] = pd.DatetimeIndex(mega_draw_df['Date']).month_name()\n",
        "mega_draw_df['day_name'] = pd.DatetimeIndex(mega_draw_df['Date']).day_name()\n",
        "mega_draw_df['day_num'] = pd.DatetimeIndex(mega_draw_df['Date']).dayofweek\n",
        "mega_draw_df['day_date'] = pd.DatetimeIndex(mega_draw_df['Date']).day\n",
        "mega_draw_df['draw_time'] = '2300'\n",
        "mega_draw_df[['num_1', 'num_2', 'num_3', 'num_4', 'num_5', 'mb']] = mega_draw_df[['num_1', 'num_2', 'num_3', 'num_4', 'num_5', 'mb']].astype(int)\n",
        "\n",
        "\n",
        "mega_draw_df.to_sql('mm_draw', conn, if_exists='replace', index = False)\n",
        "mega_weather_df.to_sql('mm_weather', conn, if_exists='replace', index = False)\n",
        "\n",
        "print(mega_draw_df)\n",
        "print(mega_weather_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mm_sql_filter = '''SELECT * FROM mm_weather WHERE (Time > 2200 AND Time < 2359)'''\n",
        "mm_weather_filtered_df = pd.read_sql(mm_sql_filter, conn)\n",
        "\n",
        "mm_weather_filtered_df['DATE_TIME'] = pd.to_datetime(mm_weather_filtered_df['DATE_TIME'])\n",
        "mm_weather_filtered_df['Date'] = pd.to_datetime(mm_weather_filtered_df['Date'])\n",
        "mm_weather_filtered_df = mm_weather_filtered_df.fillna(0)\n",
        "\n",
        "mm_weather_filtered_df.to_sql('mm_weather_filtered', conn, if_exists='replace', index = False)\n",
        "\n",
        "mm_sql_grooper = '''SELECT * FROM mm_weather_filtered GROUP BY Date'''\n",
        "mm_weather_grouped_df = pd.read_sql(mm_sql_grooper, conn)\n",
        "\n",
        "mm_weather_grouped_df.to_sql('mm_weather_grouped', conn, if_exists='replace', index = False)\n",
        "\n",
        "mm_sql_join = '''SELECT * FROM mm_draw JOIN mm_weather_grouped USING (Date)'''\n",
        "mm_join_df = pd.read_sql(mm_sql_join, conn)\n",
        "\n",
        "mm_join_df.to_sql('mm_join', conn, if_exists='replace', index = False)\n",
        "print(mm_weather_filtered_df)\n",
        "print(mm_weather_grouped_df)\n",
        "print(mm_join_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLMXBtZJnKOf",
        "outputId": "b26c8cb5-8c87-47d5-bf18-74a2966ca595"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               DATE_TIME DPTemp  DBTemp  Precip  RHumid       Date  Time\n",
            "0    2013-01-01 22:53:00     50      51    0.06      96 2013-01-01  2253\n",
            "1    2013-01-01 23:53:00     50      51    0.07      96 2013-01-01  2353\n",
            "2    2013-01-02 22:53:00     35      40    0.00      83 2013-01-02  2253\n",
            "3    2013-01-02 23:53:00     36      39    0.00      89 2013-01-02  2353\n",
            "4    2013-01-03 22:53:00     27      36    0.00      70 2013-01-03  2253\n",
            "...                  ...    ...     ...     ...     ...        ...   ...\n",
            "8981 2022-12-14 23:53:00     46      48    0.16      93 2022-12-14  2353\n",
            "8982 2022-12-15 22:53:00     32      44    0.00      63 2022-12-15  2253\n",
            "8983 2022-12-15 23:53:00     32      44    0.00      63 2022-12-15  2353\n",
            "8984 2022-12-16 22:53:00     28      43    0.00      56 2022-12-16  2253\n",
            "8985 2022-12-16 23:53:00     27      44    0.00      51 2022-12-16  2353\n",
            "\n",
            "[8986 rows x 7 columns]\n",
            "                DATE_TIME DPTemp  DBTemp  Precip  RHumid                 Date  Time\n",
            "0     2013-01-01 22:53:00     50      51    0.06      96  2013-01-01 00:00:00  2253\n",
            "1     2013-01-02 22:53:00     35      40    0.00      83  2013-01-02 00:00:00  2253\n",
            "2     2013-01-03 22:53:00     27      36    0.00      70  2013-01-03 00:00:00  2253\n",
            "3     2013-01-04 22:53:00     25      30    0.00      82  2013-01-04 00:00:00  2253\n",
            "4     2013-01-05 22:53:00     38      43    0.00      82  2013-01-05 00:00:00  2253\n",
            "...                   ...    ...     ...     ...     ...                  ...   ...\n",
            "3632  2022-12-12 22:53:00     50      54    0.00      87  2022-12-12 00:00:00  2253\n",
            "3633  2022-12-13 22:53:00     39      49    0.00      69  2022-12-13 00:00:00  2253\n",
            "3634  2022-12-14 22:21:00     46      47    0.11      97  2022-12-14 00:00:00  2221\n",
            "3635  2022-12-15 22:53:00     32      44    0.00      63  2022-12-15 00:00:00  2253\n",
            "3636  2022-12-16 22:53:00     28      43    0.00      56  2022-12-16 00:00:00  2253\n",
            "\n",
            "[3637 rows x 7 columns]\n",
            "                     Date           game  num_1  num_2  num_3  num_4  num_5  mb     month day_name  day_num  day_date draw_time            DATE_TIME DPTemp  DBTemp  Precip  RHumid  Time\n",
            "0     2013-01-01 00:00:00  Mega Millions     11     21      4     44     25  29   January  Tuesday        1         1      2300  2013-01-01 22:53:00     50      51    0.06      96  2253\n",
            "1     2013-01-04 00:00:00  Mega Millions      2     23     55     25      1  39   January   Friday        4         4      2300  2013-01-04 22:53:00     25      30    0.00      82  2253\n",
            "2     2013-01-08 00:00:00  Mega Millions      3     38     20     21     42  19   January  Tuesday        1         8      2300  2013-01-08 22:53:00     40      50    0.00      68  2253\n",
            "3     2013-01-11 00:00:00  Mega Millions     29     56     24     34     30   1   January   Friday        4        11      2300  2013-01-11 22:53:00     60      61    0.00      97  2253\n",
            "4     2013-01-15 00:00:00  Mega Millions     19      1     41     12      6  14   January  Tuesday        1        15      2300  2013-01-15 22:51:00     55      57    0.00      94  2251\n",
            "...                   ...            ...    ...    ...    ...    ...    ...  ..       ...      ...      ...       ...       ...                  ...    ...     ...     ...     ...   ...\n",
            "1035  2022-12-02 00:00:00  Mega Millions     52     46     21      1     36  16  December   Friday        4         2      2300  2022-12-02 22:53:00     44      54    0.00      69  2253\n",
            "1036  2022-12-06 00:00:00  Mega Millions     28     19     16     15     47  13  December  Tuesday        1         6      2300  2022-12-06 22:51:00     54      54    0.00     100  2251\n",
            "1037  2022-12-09 00:00:00  Mega Millions     61     19      8     53     69  19  December   Friday        4         9      2300  2022-12-09 22:53:00     56      57    0.00      96  2253\n",
            "1038  2022-12-13 00:00:00  Mega Millions     48     58     14     68     22   6  December  Tuesday        1        13      2300  2022-12-13 22:53:00     39      49    0.00      69  2253\n",
            "1039  2022-12-16 00:00:00  Mega Millions     40     56     35      8     53  11  December   Friday        4        16      2300  2022-12-16 22:53:00     28      43    0.00      56  2253\n",
            "\n",
            "[1040 rows x 19 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mm_num_list = list(range(1,71))\n",
        "mb_list = list(range(1,26))\n",
        "\n",
        "counts_num_1={}\n",
        "for num in mm_num_list:\n",
        "  count = mega_draw_df['num_1'].value_counts()[num]\n",
        "  counts_num_1.update({num:count})\n",
        "\n",
        "mega_counts_df = pd.Series(counts_num_1).to_frame('count_num_1')\n",
        "\n",
        "mega_counts_df.reset_index(inplace=True)\n",
        "mega_counts_df = mega_counts_df.rename(columns = {'index':'number'})\n",
        "\n",
        "counts_num_2={}\n",
        "for num in mm_num_list:\n",
        "  count = mega_draw_df['num_2'].value_counts()[num]\n",
        "  counts_num_2.update({num:count})\n",
        "mega_counts_df['count_num_2'] = mega_counts_df['number'].map(counts_num_2)\n",
        "\n",
        "counts_num_3={}\n",
        "for num in mm_num_list:\n",
        "  count = mega_draw_df['num_3'].value_counts()[num]\n",
        "  counts_num_3.update({num:count})\n",
        "mega_counts_df['count_num_3'] = mega_counts_df['number'].map(counts_num_3)\n",
        "\n",
        "counts_num_4={}\n",
        "for num in mm_num_list:\n",
        "  count = mega_draw_df['num_4'].value_counts()[num]\n",
        "  counts_num_4.update({num:count})\n",
        "mega_counts_df['count_num_4'] = mega_counts_df['number'].map(counts_num_4)\n",
        "\n",
        "counts_num_5={}\n",
        "for num in mm_num_list:\n",
        "  count = mega_draw_df['num_5'].value_counts()[num]\n",
        "  counts_num_5.update({num:count})\n",
        "mega_counts_df['count_num_5'] = mega_counts_df['number'].map(counts_num_5)\n",
        "\n",
        "counts_mb={}\n",
        "for num in mb_list:\n",
        "  count = mega_draw_df['mb'].value_counts()[num]\n",
        "  counts_mb.update({num:count})\n",
        "mega_counts_df['count_mb'] = mega_counts_df['number'].map(counts_mb)\n",
        "mega_counts_df['count_mb'] = mega_counts_df['count_mb'].fillna(0).astype(int)\n",
        "\n",
        "col_list= list(mega_counts_df)\n",
        "col_list.remove('number')\n",
        "col_list.remove('count_mb')\n",
        "\n",
        "mega_counts_df['totals'] = mega_counts_df[col_list].sum(axis=1)\n",
        "mega_counts_df\n",
        "\n",
        "print(mega_counts_df)\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzdLMyiRdQNU",
        "outputId": "1f74d769-236e-4a95-8ddc-da9ee4c50220"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['count_num_1', 'count_num_2', 'count_num_3', 'count_num_4', 'count_num_5']\n",
            "    number  count_num_1  count_num_2  count_num_3  count_num_4  count_num_5  count_mb  totals\n",
            "0        1           25           30           25           36           29        73     145\n",
            "1        2           35           41           34           39           27        66     176\n",
            "2        3           30           30           30           43           36        70     169\n",
            "3        4           35           41           39           31           25        75     171\n",
            "4        5           32           29           30           34           29        57     154\n",
            "..     ...          ...          ...          ...          ...          ...       ...     ...\n",
            "65      66           11           14           15           15           13         0      68\n",
            "66      67           14            7           14            5           11         0      51\n",
            "67      68           16           15            9           15           13         0      68\n",
            "68      69            8           17           11           12           12         0      60\n",
            "69      70           11           17           14            9           11         0      62\n",
            "\n",
            "[70 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLFwInXReKQM",
        "outputId": "4df7e363-19c4-4657-fda3-d38dbbf15d03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Date       game  num_1  num_2  num_3  num_4  num_5  pb     month   day_name  day_num  day_date draw_time  mb\n",
            "0    2010-02-03  Powerball     12     44     15     18      1  24  February  Wednesday        2         3      2300  42\n",
            "1    2010-02-06  Powerball     14     15     48      4     24   4  February   Saturday        5         6      2300  41\n",
            "2    2010-02-10  Powerball     16     32     46      9     45  34  February  Wednesday        2        10      2300  26\n",
            "3    2010-02-13  Powerball     47     16     31     24     46   1  February   Saturday        5        13      2300  47\n",
            "4    2010-02-17  Powerball      5     10     39     17     35  15  February  Wednesday        2        17      2300  38\n",
            "...         ...        ...    ...    ...    ...    ...    ...  ..       ...        ...      ...       ...       ...  ..\n",
            "1445 2023-03-04  Powerball     16      7     61     62     24  16     March   Saturday        5         4      2300   2\n",
            "1446 2023-03-06  Powerball     31      7     26      2     18   4     March     Monday        0         6      2300  12\n",
            "1447 2023-03-08  Powerball     49     70     56     31     45   4     March  Wednesday        2         8      2300  11\n",
            "1448 2023-03-11  Powerball     63      6     73     66     23  24     March   Saturday        5        11      2300   9\n",
            "1449 2023-03-13  Powerball     24     64     34     56     20   4     March     Monday        0        13      2300   6\n",
            "\n",
            "[1450 rows x 14 columns]\n",
            "                 DATE_TIME DPTemp DBTemp Precip RHumid       Date  Time\n",
            "0      2014-03-13 00:53:00     33     51   0.00     50 2014-03-13  0053\n",
            "1      2014-03-13 01:00:00     33     51    NaN     50 2014-03-13  0100\n",
            "2      2014-03-13 01:53:00     31     49   0.00     50 2014-03-13  0153\n",
            "3      2014-03-13 02:53:00     31     48   0.00     52 2014-03-13  0253\n",
            "4      2014-03-13 03:53:00     29     47   0.00     50 2014-03-13  0353\n",
            "...                    ...    ...    ...    ...    ...        ...   ...\n",
            "119506 2023-03-12 23:53:00     62     64      T     93 2023-03-12  2353\n",
            "119507 2023-03-12 23:59:00    NaN    NaN    NaN    NaN 2023-03-12  2359\n",
            "119508 2023-03-13 00:53:00     62     63    NaN     97 2023-03-13  0053\n",
            "119509 2023-03-13 01:53:00     62     63   0.05     97 2023-03-13  0153\n",
            "119510 2023-03-13 23:59:00    NaN    NaN    NaN    NaN 2023-03-13  2359\n",
            "\n",
            "[119511 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "pb_draw_file = (pb_draw_file_url)\n",
        "pb_weather_file = (pb_weather_file_url)\n",
        "\n",
        "pb_draw_df = pd.read_csv(pb_draw_file, engine='python', parse_dates= {\"draw_date\" : [\"year\",\"month\",\"day\"]})\n",
        "pb_weather_df = pd.read_csv(pb_weather_file, engine='python')\n",
        "\n",
        "pb_weather_df['Date'] = pd.to_datetime(pb_weather_df['DATE_TIME']).dt.strftime('%Y%m%d')\n",
        "pb_weather_df['Time'] = pd.to_datetime(pb_weather_df['DATE_TIME']).dt.strftime('%H%M')\n",
        "\n",
        "pb_weather_df['Date'] = pd.to_datetime(pb_weather_df['Date'])\n",
        "pb_weather_df['DATE_TIME'] = pd.to_datetime(pb_weather_df['DATE_TIME'])\n",
        "\n",
        "pb_draw_df.rename({'draw_date': 'Date'}, axis=1, inplace=True)\n",
        "pb_draw_df['Date'] = pd.to_datetime(pb_draw_df['Date']).dt.strftime('%Y%m%d')\n",
        "pb_draw_df['Date'] = pd.to_datetime(pb_draw_df['Date'])\n",
        "pb_draw_df['month'] = pd.DatetimeIndex(pb_draw_df['Date']).month_name()\n",
        "pb_draw_df['day_name'] = pd.DatetimeIndex(pb_draw_df['Date']).day_name()\n",
        "pb_draw_df['day_num'] = pd.DatetimeIndex(pb_draw_df['Date']).dayofweek\n",
        "pb_draw_df['day_date'] = pd.DatetimeIndex(pb_draw_df['Date']).day\n",
        "pb_draw_df['draw_time'] = '2300'\n",
        "pb_draw_df[['num_1', 'num_2', 'num_3', 'num_4', 'num_5', 'mb']] = mega_draw_df[['num_1', 'num_2', 'num_3', 'num_4', 'num_5', 'mb']].astype(int)\n",
        "\n",
        "pb_draw_df.to_sql('pb_draw', conn, if_exists='replace', index = False)\n",
        "pb_weather_df.to_sql('pb_weather', conn, if_exists='replace', index = False)\n",
        "\n",
        "print(pb_draw_df)\n",
        "print(pb_weather_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pb_sql_filter = '''SELECT * FROM pb_weather WHERE (Time > 2200 AND Time < 2359)'''\n",
        "pb_weather_filtered_df = pd.read_sql(pb_sql_filter, conn)\n",
        "pb_weather_filtered_df['DATE_TIME'] = pd.to_datetime(pb_weather_filtered_df['DATE_TIME'])\n",
        "pb_weather_filtered_df['Date'] = pd.to_datetime(pb_weather_filtered_df['Date'])\n",
        "pb_weather_filtered_df = pb_weather_filtered_df.fillna(0)\n",
        "\n",
        "pb_weather_filtered_df.to_sql('pb_weather_filtered', conn, if_exists='replace', index = False)\n",
        "\n",
        "pb_sql_grooper = '''SELECT * FROM pb_weather_filtered GROUP BY Date'''\n",
        "pb_weather_grouped_df = pd.read_sql(pb_sql_grooper, conn)\n",
        "\n",
        "pb_weather_grouped_df.to_sql('pb_weather_grouped', conn, if_exists='replace', index = False)\n",
        "\n",
        "pb_sql_join = '''SELECT * FROM pb_draw JOIN pb_weather_grouped USING (Date)'''\n",
        "pb_join_df = pd.read_sql(pb_sql_join, conn)\n",
        "\n",
        "pb_join_df.to_sql('pb_join', conn, if_exists='replace', index = False)\n",
        "print(pb_weather_filtered_df)\n",
        "print(pb_weather_grouped_df)\n",
        "print(pb_join_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REFZ6a_BDZOF",
        "outputId": "7dca5126-b681-4fac-fe1b-ad07ba140681"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               DATE_TIME DPTemp DBTemp Precip RHumid       Date  Time\n",
            "0    2014-03-13 22:53:00     33     41   0.00     73 2014-03-13  2253\n",
            "1    2014-03-13 23:53:00     32     38   0.00     79 2014-03-13  2353\n",
            "2    2014-03-14 22:53:00     36     45   0.00     71 2014-03-14  2253\n",
            "3    2014-03-14 23:53:00     33     41   0.00     73 2014-03-14  2353\n",
            "4    2014-03-15 22:53:00     50     57   0.00     78 2014-03-15  2253\n",
            "...                  ...    ...    ...    ...    ...        ...   ...\n",
            "8186 2023-03-12 22:37:00     64     65      0     97 2023-03-12  2237\n",
            "8187 2023-03-12 22:46:00     64     65      0     97 2023-03-12  2246\n",
            "8188 2023-03-12 22:53:00     64     65   0.05     97 2023-03-12  2253\n",
            "8189 2023-03-12 23:18:00     63     64      0     96 2023-03-12  2318\n",
            "8190 2023-03-12 23:53:00     62     64      T     93 2023-03-12  2353\n",
            "\n",
            "[8191 rows x 7 columns]\n",
            "                DATE_TIME DPTemp DBTemp Precip RHumid                 Date  Time\n",
            "0     2014-03-13 22:53:00     33     41   0.00     73  2014-03-13 00:00:00  2253\n",
            "1     2014-03-14 22:53:00     36     45   0.00     71  2014-03-14 00:00:00  2253\n",
            "2     2014-03-15 22:53:00     50     57   0.00     78  2014-03-15 00:00:00  2253\n",
            "3     2014-03-16 22:03:00     59     63   0.05     88  2014-03-16 00:00:00  2203\n",
            "4     2014-03-17 22:07:00     61     64   0.02     88  2014-03-17 00:00:00  2207\n",
            "...                   ...    ...    ...    ...    ...                  ...   ...\n",
            "3277  2023-03-08 22:53:00     44     63   0.00     50  2023-03-08 00:00:00  2253\n",
            "3278  2023-03-09 22:10:00     59     64      0     84  2023-03-09 00:00:00  2210\n",
            "3279  2023-03-10 22:53:00     62     66   0.00     87  2023-03-10 00:00:00  2253\n",
            "3280  2023-03-11 22:53:00     50     58   0.00     75  2023-03-11 00:00:00  2253\n",
            "3281  2023-03-12 22:06:00     65     65      0    100  2023-03-12 00:00:00  2206\n",
            "\n",
            "[3282 rows x 7 columns]\n",
            "                     Date       game  num_1  num_2  num_3  num_4  num_5  pb  month   day_name  day_num  day_date draw_time  mb            DATE_TIME DPTemp DBTemp Precip RHumid  Time\n",
            "0     2014-03-15 00:00:00  Powerball     21     30     44     42     50   9  March   Saturday        5        15      2300   6  2014-03-15 22:53:00     50     57   0.00     78  2253\n",
            "1     2014-03-19 00:00:00  Powerball     12     43     22     44     33  14  March  Wednesday        2        19      2300  15  2014-03-19 22:53:00     50     55   0.00     83  2253\n",
            "2     2014-03-22 00:00:00  Powerball     25     12     15     33     22  15  March   Saturday        5        22      2300   2  2014-03-22 22:53:00     54     63   0.00     73  2253\n",
            "3     2014-03-26 00:00:00  Powerball     12     22      5     38     56  21  March  Wednesday        2        26      2300  22  2014-03-26 22:53:00     31     50   0.00     48  2253\n",
            "4     2014-03-29 00:00:00  Powerball     23      8     42     39     40  17  March   Saturday        5        29      2300  24  2014-03-29 22:53:00     47     63   0.00     56  2253\n",
            "...                   ...        ...    ...    ...    ...    ...    ...  ..    ...        ...      ...       ...       ...  ..                  ...    ...    ...    ...    ...   ...\n",
            "1014  2023-03-01 00:00:00  Powerball     33     56     21     45     36   4  March  Wednesday        2         1      2300  12  2023-03-01 22:39:00     67     69      0     93  2239\n",
            "1015  2023-03-04 00:00:00  Powerball     16      7     61     62     24  16  March   Saturday        5         4      2300   2  2023-03-04 22:53:00     52     62   0.00     70  2253\n",
            "1016  2023-03-06 00:00:00  Powerball     31      7     26      2     18   4  March     Monday        0         6      2300  12  2023-03-06 22:53:00     67     71   0.00     87  2253\n",
            "1017  2023-03-08 00:00:00  Powerball     49     70     56     31     45   4  March  Wednesday        2         8      2300  11  2023-03-08 22:53:00     44     63   0.00     50  2253\n",
            "1018  2023-03-11 00:00:00  Powerball     63      6     73     66     23  24  March   Saturday        5        11      2300   9  2023-03-11 22:53:00     50     58   0.00     75  2253\n",
            "\n",
            "[1019 rows x 20 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%HTML\n",
        "<div class='tableauPlaceholder' id='viz1679398882113' style='position: relative'><noscript><a href='#'><img alt='Dashboard 1 ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Me&#47;MegamillionsNumbers&#47;Dashboard1&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='MegamillionsNumbers&#47;Dashboard1' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Me&#47;MegamillionsNumbers&#47;Dashboard1&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1679398882113');                    var vizElement = divElement.getElementsByTagName('object')[0];                    if ( divElement.offsetWidth > 800 ) { vizElement.style.minWidth='420px';vizElement.style.maxWidth='650px';vizElement.style.width='100%';vizElement.style.minHeight='587px';vizElement.style.maxHeight='887px';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.minWidth='420px';vizElement.style.maxWidth='650px';vizElement.style.width='100%';vizElement.style.minHeight='587px';vizElement.style.maxHeight='887px';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';} else { vizElement.style.width='100%';vizElement.style.height='1677px';}                     var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        },
        "id": "FKpaHver-7pI",
        "outputId": "0cfa5c09-66e4-4b8e-e4a5-10de8a5d936c"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class='tableauPlaceholder' id='viz1679398882113' style='position: relative'><noscript><a href='#'><img alt='Dashboard 1 ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Me&#47;MegamillionsNumbers&#47;Dashboard1&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='MegamillionsNumbers&#47;Dashboard1' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Me&#47;MegamillionsNumbers&#47;Dashboard1&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1679398882113');                    var vizElement = divElement.getElementsByTagName('object')[0];                    if ( divElement.offsetWidth > 800 ) { vizElement.style.minWidth='420px';vizElement.style.maxWidth='650px';vizElement.style.width='100%';vizElement.style.minHeight='587px';vizElement.style.maxHeight='887px';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.minWidth='420px';vizElement.style.maxWidth='650px';vizElement.style.width='100%';vizElement.style.minHeight='587px';vizElement.style.maxHeight='887px';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';} else { vizElement.style.width='100%';vizElement.style.height='1677px';}                     var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idrfC-EBeKQN"
      },
      "outputs": [],
      "source": [
        "#weather_df = weather_df.astype({\"HourlyRelativeHumidity\": float})\n",
        "weather_filter_df = mega_weather_df.query('DBTemp == 42 & RHumid == 73')\n",
        "#weather_df.dtypes\n",
        "#weather_filter_df\n",
        "weather_date_unique = weather_filter_df['Date'].unique()\n",
        "weather_date_unique_df = pd.DataFrame(weather_date_unique, columns=['date_time'])\n",
        "weather_date_unique_df['date_time'] = pd.to_datetime(weather_date_unique_df['date_time'])\n",
        "\n",
        "weather_date_unique_df['time_only'] = pd.to_datetime(weather_date_unique_df['date_time']).dt.time\n",
        "weather_date_unique_df['draw_date'] = pd.to_datetime(weather_date_unique_df['date_time']).dt.date\n",
        "weather_date_unique_df['draw_date'] = pd.to_datetime(weather_date_unique_df['draw_date'])\n",
        "weather_date_unique_df['draw_date'] = weather_date_unique_df['draw_date'].dt.strftime('%m/%d/%Y')\n",
        "\n",
        "\n",
        "\n",
        "dates_list = weather_date_unique_df['draw_date'].values.tolist()\n",
        "\n",
        "#with pd.option_context('display.max_rows', None,\n",
        "#                       'display.max_columns', None,\n",
        "#                       'display.precision', 3,\n",
        "#                       ):\n",
        "#    print(weather_date_unique_df)\n",
        "dates_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yj1afnV9eKQN"
      },
      "outputs": [],
      "source": [
        "arr = mega_draw_df.iloc[:, 2:7].values\n",
        "\n",
        "mega_draw_df['check'] = np.any(((arr[:, 1:] - arr[:, :-1]) == 1),axis=1).astype(int)\n",
        "with pd.option_context('display.max_rows', None,\n",
        "                       'display.max_columns', None,\n",
        "                       'display.precision', 3,\n",
        "                       ):\n",
        "    print(mega_draw_df)\n",
        "\n",
        "mega_draw_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rf1pdLpXeKQN"
      },
      "outputs": [],
      "source": [
        "counts_1 = mega_draw_df['num_1'].value_counts()\n",
        "counts_2 = mega_draw_df['num_2'].value_counts()\n",
        "counts_3 = mega_draw_df['num_3'].value_counts()\n",
        "counts_4 = mega_draw_df['num_4'].value_counts()\n",
        "counts_5 = mega_draw_df['num_5'].value_counts()\n",
        "counts_MB = mega_draw_df['MB'].value_counts()\n",
        "#counts_df.columns = ['num_1', 'counts_1']\n",
        "#with pd.option_context('display.max_rows', None,\n",
        "                       #'display.max_columns', None,\n",
        "                       #'display.precision', 3,\n",
        "                       #):\n",
        "    #print(counts_1, counts_2)\n",
        "counts_df = pd.concat([counts_1, counts_2, counts_3, counts_4, counts_5, counts_MB], axis=1)\n",
        "with pd.option_context('display.max_rows', None,\n",
        "                       'display.max_columns', None,\n",
        "                       'display.precision', 3,\n",
        "                       ):\n",
        "    print(counts_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIvpommOeKQN"
      },
      "outputs": [],
      "source": [
        "mega_draw_df[0:2][['num_1', 'num_5']] #Slice the dataframe by selected row indexes and a list of column names.\n",
        "mega_draw_df['num_3'][:4] #create a series from the first 4 rows (0 - 3) of the column string \"num_3\".\n",
        "dft['num_2' : 'num_5'] #Slice transposed dataframe with row name from 'num_2 up to and including 'num_5'.\n",
        "dft.loc['num_3', 2] #Row/Column based indexing. loc uses lables to slice.\n",
        "mega_draw_df.iloc[1:100, :] #Slice dataframe by rows 1 - 99 and all columns. iloc uses integers as index positions to slice.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-m5lx8RQeKQO"
      },
      "outputs": [],
      "source": [
        "mega_draw_df['draw_date'] = pd.to_datetime(mega_draw_df['draw_date'])\n",
        "date_df = mega_draw_df[mega_draw_df['draw_date'].dt.month == 12]\n",
        "\n",
        "counts_1 = date_df['num_1'].value_counts()\n",
        "counts_2 = date_df['num_2'].value_counts()\n",
        "counts_3 = date_df['num_3'].value_counts()\n",
        "counts_4 = date_df['num_4'].value_counts()\n",
        "counts_5 = date_df['num_5'].value_counts()\n",
        "counts_MB = date_df['MB'].value_counts()\n",
        "counts_df = pd.concat([counts_1, counts_2, counts_3, counts_4, counts_5, counts_MB], axis=1)\n",
        "\n",
        "with pd.option_context('display.max_rows', None,\n",
        "                       'display.max_columns', None,\n",
        "                       'display.precision', 3,\n",
        "                       ):\n",
        "    print(counts_df)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TWf27M7eKQO"
      },
      "outputs": [],
      "source": [
        "mega_draw_df['draw_date'].astype(str)\n",
        "df2 = mega_draw_df[mega_draw_df['draw_date'].isin(dates_list)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with pd.option_context('display.max_rows', None,\n",
        "                       'display.max_columns', None,\n",
        "                       'display.precision', 3,\n",
        "                       ):\n",
        "    print(df2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Q_TPCOkeKQO"
      },
      "outputs": [],
      "source": [
        "counts_1 = df2['num_1'].value_counts()\n",
        "counts_2 = df2['num_2'].value_counts()\n",
        "counts_3 = df2['num_3'].value_counts()\n",
        "counts_4 = df2['num_4'].value_counts()\n",
        "counts_5 = df2['num_5'].value_counts()\n",
        "counts_MB = df2['MB'].value_counts()\n",
        "counts_MB_df= pd.DataFrame(counts_MB)\n",
        "sorted_MB = counts_MB_df.sort_values('MB', ascending=False)\n",
        "counts_df = pd.concat([counts_1, counts_2, counts_3, counts_4, counts_5], axis=1)\n",
        "counts_df['totals'] = counts_df.sum(axis=1, skipna=True)\n",
        "sorted_df = counts_df.sort_values('totals', ascending=False)\n",
        "\n",
        "with pd.option_context('display.max_rows', None,\n",
        "                       'display.max_columns', None,\n",
        "                       'display.precision', 3,\n",
        "                       ):\n",
        "    print(sorted_df)\n",
        "    print(sorted_MB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flLJ48T8eKQO"
      },
      "outputs": [],
      "source": [
        "draw_list=(sorted_df.index.values)\n",
        "draw_list_MB=(sorted_MB.index.values)\n",
        "print(draw_list)\n",
        "print(draw_list_MB)\n",
        "type(draw_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0XLuXnKeKQO"
      },
      "outputs": [],
      "source": [
        "draw_list = list(draw_list)\n",
        "new_list1 = random.sample(draw_list, 5)\n",
        "new_list1 = sorted(new_list1)\n",
        "draw_list_MB = list(draw_list_MB)\n",
        "new_list_MB = random.sample(draw_list_MB, 1)\n",
        "#sorted([str(x) for x in new_list1])\n",
        "print(new_list1 + new_list_MB)\n",
        "type(new_list1[1])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}