{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mikdown/Lottery-Picker/blob/master/colab_lotto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ciAogFP5eKQJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', 20)\n",
        "pd.set_option('display.width', 1000)\n",
        "import numpy as np\n",
        "import datetime\n",
        "import random\n",
        "import sqlite3\n",
        "mega_draw_file_url = (\"https://raw.githubusercontent.com/Mikdown/Lottery-Picker/master/assets/megamillions.csv\")\n",
        "mega_weather_file_url = (\"https://raw.githubusercontent.com/Mikdown/Lottery-Picker/master/assets/mega_weather.csv\")\n",
        "pb_draw_file_url = (\"https://raw.githubusercontent.com/Mikdown/Lottery-Picker/master/assets/powerball.csv\")\n",
        "pb_weather_file_url = (\"https://raw.githubusercontent.com/Mikdown/Lottery-Picker/master/assets/pb_weather.csv\")\n",
        "\n",
        "conn = sqlite3.connect('lottery_data.db')\n",
        "\n",
        "cur = conn.cursor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO-6wKUjeKQK"
      },
      "source": [
        "###The following four code cells meet the first and second feature requirements:\n",
        "1. Feature 1. Read two data files (CSV).\n",
        "2. Feature 2. Clean your data.\n",
        "    - Four CSV files are read in from Github and cleaned(transformed) with Pandas. \n",
        "3. Feature 1. Set up a local database and read data in with SQLite.\n",
        "4. Feature 2. Perform a SQL join.\n",
        "    - After transformation the files are read into a local SQLite3 DB to be used for futher analysis.\n",
        "    - Data is read in from the database and a SQL join is performed on 2 tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKqyYAW0eKQL",
        "outputId": "4cf4a192-98bc-4174-8cab-2094f9972695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Date           game  num_1  num_2  num_3  num_4  num_5  mb    month  day_name  day_num  day_date draw_time\n",
            "0     20031205  Mega Millions     12     44     15     18      1  42  January  Thursday        3         1      2300\n",
            "1     20031209  Mega Millions     14     15     48      4     24  41  January  Thursday        3         1      2300\n",
            "2     20031212  Mega Millions     16     32     46      9     45  26  January  Thursday        3         1      2300\n",
            "3     20031216  Mega Millions     47     16     31     24     46  47  January  Thursday        3         1      2300\n",
            "4     20031219  Mega Millions      5     10     39     17     35  38  January  Thursday        3         1      2300\n",
            "...        ...            ...    ...    ...    ...    ...    ...  ..      ...       ...      ...       ...       ...\n",
            "2006  20230224  Mega Millions     22     49      2     65     67   7  January  Thursday        3         1      2300\n",
            "2007  20230228  Mega Millions     59     52     40     14     16  13  January  Thursday        3         1      2300\n",
            "2008  20230303  Mega Millions     39      8     67     36     25  11  January  Thursday        3         1      2300\n",
            "2009  20230307  Mega Millions     15     69     28     25     22  21  January  Thursday        3         1      2300\n",
            "2010  20230310  Mega Millions     60      9     20     59     63   5  January  Thursday        3         1      2300\n",
            "\n",
            "[2011 rows x 13 columns]\n",
            "                 DATE_TIME DPTemp  DBTemp  Precip  RHumid      Date  Time\n",
            "0      2013-01-01 00:53:00     36      47     0.0      66  20130101  0053\n",
            "1      2013-01-01 01:53:00     36      43     0.0      76  20130101  0153\n",
            "2      2013-01-01 02:51:00     37      45     0.0      76  20130101  0251\n",
            "3      2013-01-01 02:53:00     37      44     0.0      76  20130101  0253\n",
            "4      2013-01-01 03:53:00     38      45     0.0      77  20130101  0353\n",
            "...                    ...    ...     ...     ...     ...       ...   ...\n",
            "115441 2022-12-16 22:53:00     28      43     0.0      56  20221216  2253\n",
            "115442 2022-12-16 23:53:00     27      44     0.0      51  20221216  2353\n",
            "115443 2022-12-16 23:59:00    NaN       0     0.0       0  20221216  2359\n",
            "115444 2022-12-17 00:53:00     28      45     0.0      52  20221217  0053\n",
            "115445 2022-12-17 01:53:00     28      45     0.0      52  20221217  0153\n",
            "\n",
            "[115446 rows x 7 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DATE_TIME    datetime64[ns]\n",
              "DPTemp               object\n",
              "DBTemp                int64\n",
              "Precip              float64\n",
              "RHumid                int64\n",
              "Date                  int64\n",
              "Time                 object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "mega_draw_file = (mega_draw_file_url)\n",
        "mega_weather_file = (mega_weather_file_url)\n",
        "\n",
        "mega_draw_df = pd.read_csv(mega_draw_file, engine='python', parse_dates= {\"draw_date\" : [\"year\",\"month\",\"day\"]})\n",
        "mega_weather_df = pd.read_csv(mega_weather_file, engine='python')\n",
        "\n",
        "#Split the \"DATE_TIME\" column into 2 seperate columns \"Date\" and \"Time\".\n",
        "\n",
        "mega_weather_df['Date'] = pd.to_datetime(mega_weather_df['DATE_TIME']).dt.strftime('%Y%m%d').astype(int)\n",
        "mega_weather_df['Time'] = pd.to_datetime(mega_weather_df['DATE_TIME']).dt.strftime('%H%M')\n",
        "\n",
        "mega_weather_df['DATE_TIME'] = pd.to_datetime(mega_weather_df['DATE_TIME'])\n",
        "\n",
        "mega_draw_df.rename({'draw_date': 'Date'}, axis=1, inplace=True)\n",
        "mega_draw_df['Date'] = pd.to_datetime(mega_draw_df['Date']).dt.strftime('%Y%m%d').astype(int)\n",
        "mega_draw_df['month'] = pd.DatetimeIndex(mega_draw_df['Date']).month_name()\n",
        "mega_draw_df['day_name'] = pd.DatetimeIndex(mega_draw_df['Date']).day_name()\n",
        "mega_draw_df['day_num'] = pd.DatetimeIndex(mega_draw_df['Date']).dayofweek\n",
        "mega_draw_df['day_date'] = pd.DatetimeIndex(mega_draw_df['Date']).day\n",
        "mega_draw_df['draw_time'] = '2300'\n",
        "\n",
        "mega_draw_df.to_sql('mm_draw', conn, if_exists='replace', index = False)\n",
        "mega_weather_df.to_sql('mm_weather', conn, if_exists='replace', index = False)\n",
        "\n",
        "print(mega_draw_df)\n",
        "print(mega_weather_df)\n",
        "mega_weather_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLFwInXReKQM",
        "outputId": "b56864e2-e745-4d5c-9475-91539d3b3d5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Date       game  num_1  num_2  num_3  num_4  num_5  pb    month  day_name  day_num  day_date draw_time\n",
            "0     20100203  Powerball     37     52     22     36     17  24  January  Thursday        3         1      2300\n",
            "1     20100206  Powerball     22     54     52     14     59   4  January  Thursday        3         1      2300\n",
            "2     20100210  Powerball     29      8     37     38      5  34  January  Thursday        3         1      2300\n",
            "3     20100213  Powerball     14     10     40     51     30   1  January  Thursday        3         1      2300\n",
            "4     20100217  Powerball     36      7     26      8     19  15  January  Thursday        3         1      2300\n",
            "...        ...        ...    ...    ...    ...    ...    ...  ..      ...       ...      ...       ...       ...\n",
            "1445  20230304  Powerball     10     40     16     18     66  16  January  Thursday        3         1      2300\n",
            "1446  20230306  Powerball     69     58     13     29      2   4  January  Thursday        3         1      2300\n",
            "1447  20230308  Powerball     43     69     26     27     61   4  January  Thursday        3         1      2300\n",
            "1448  20230311  Powerball     33     58     11     43     20  24  January  Thursday        3         1      2300\n",
            "1449  20230313  Powerball      3     46     24     10     63   4  January  Thursday        3         1      2300\n",
            "\n",
            "[1450 rows x 13 columns]\n",
            "                  DATE_TIME DPTemp DBTemp Precip RHumid      Date  Time\n",
            "0       2014-03-13T00:53:00     33     51   0.00     50  20140313  0053\n",
            "1       2014-03-13T01:00:00     33     51    NaN     50  20140313  0100\n",
            "2       2014-03-13T01:53:00     31     49   0.00     50  20140313  0153\n",
            "3       2014-03-13T02:53:00     31     48   0.00     52  20140313  0253\n",
            "4       2014-03-13T03:53:00     29     47   0.00     50  20140313  0353\n",
            "...                     ...    ...    ...    ...    ...       ...   ...\n",
            "119506  2023-03-12T23:53:00     62     64      T     93  20230312  2353\n",
            "119507  2023-03-12T23:59:00    NaN    NaN    NaN    NaN  20230312  2359\n",
            "119508  2023-03-13T00:53:00     62     63    NaN     97  20230313  0053\n",
            "119509  2023-03-13T01:53:00     62     63   0.05     97  20230313  0153\n",
            "119510  2023-03-13T23:59:00    NaN    NaN    NaN    NaN  20230313  2359\n",
            "\n",
            "[119511 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "pb_draw_file = (pb_draw_file_url)\n",
        "pb_weather_file = (pb_weather_file_url)\n",
        "\n",
        "pb_draw_df = pd.read_csv(pb_draw_file, engine='python', parse_dates= {\"draw_date\" : [\"year\",\"month\",\"day\"]})\n",
        "pb_weather_df = pd.read_csv(pb_weather_file, engine='python')\n",
        "\n",
        "pb_weather_df['Date'] = pd.to_datetime(pb_weather_df['DATE_TIME']).dt.strftime('%Y%m%d').astype(int)\n",
        "pb_weather_df['Time'] = pd.to_datetime(pb_weather_df['DATE_TIME']).dt.strftime('%H%M')\n",
        "\n",
        "pb_draw_df.rename({'draw_date': 'Date'}, axis=1, inplace=True)\n",
        "pb_draw_df['Date'] = pd.to_datetime(pb_draw_df['Date']).dt.strftime('%Y%m%d').astype(int)\n",
        "pb_draw_df['month'] = pd.DatetimeIndex(pb_draw_df['Date']).month_name()\n",
        "pb_draw_df['day_name'] = pd.DatetimeIndex(pb_draw_df['Date']).day_name()\n",
        "pb_draw_df['day_num'] = pd.DatetimeIndex(pb_draw_df['Date']).dayofweek\n",
        "pb_draw_df['day_date'] = pd.DatetimeIndex(pb_draw_df['Date']).day\n",
        "pb_draw_df['draw_time'] = '2300'\n",
        "\n",
        "pb_draw_df.to_sql('pb_draw', conn, if_exists='replace', index = False)\n",
        "pb_weather_df.to_sql('pb_weather', conn, if_exists='replace', index = False)\n",
        "\n",
        "print(pb_draw_df)\n",
        "print(pb_weather_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mm_sql_filter = '''SELECT * FROM mm_weather WHERE (Time > 2200 AND Time < 2359)'''\n",
        "mm_weather_filtered_df = pd.read_sql(mm_sql_filter, conn)\n",
        "\n",
        "mm_weather_filtered_df['DATE_TIME'] = pd.to_datetime(mm_weather_filtered_df['DATE_TIME'])\n",
        "mm_weather_filtered_df = mm_weather_filtered_df.fillna(0)\n",
        "mm_weather_grouped_df = mm_weather_filtered_df.groupby([mm_weather_filtered_df['DATE_TIME'].dt.date])['DBTemp', 'RHumid'].mean()\n",
        "print(mm_weather_grouped_df)\n",
        "\n",
        "mm_weather_filtered_df.to_sql('mm_weather_filtered', conn, if_exists='replace', index = False)\n",
        "mm_weather_grouped_df.to_sql('mm_weather_grouped', conn, if_exists='replace', index = False)\n",
        "#mm_join_df = pd.read_sql(mm_sql_join, conn)\n",
        "\n",
        "#mm_join_df.to_sql('mm_join', conn, if_exists='replace', index = False)\n",
        "\n",
        "#print(mm_join_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLMXBtZJnKOf",
        "outputId": "9e5521d9-5e95-42d9-c70c-6874570ece93"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               DBTemp     RHumid\n",
            "DATE_TIME                       \n",
            "2013-01-01  51.000000  96.000000\n",
            "2013-01-02  39.500000  86.000000\n",
            "2013-01-03  36.000000  71.500000\n",
            "2013-01-04  30.000000  82.000000\n",
            "2013-01-05  43.000000  81.000000\n",
            "...               ...        ...\n",
            "2022-12-12  53.500000  86.500000\n",
            "2022-12-13  49.000000  67.500000\n",
            "2022-12-14  47.428571  95.285714\n",
            "2022-12-15  44.000000  63.000000\n",
            "2022-12-16  43.500000  53.500000\n",
            "\n",
            "[3637 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-a09455266b48>:6: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  mm_weather_grouped_df = mm_weather_filtered_df.groupby([mm_weather_filtered_df['DATE_TIME'].dt.date])['DBTemp', 'RHumid'].mean()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3637"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pb_sql_filter = '''SELECT * FROM pb_weather WHERE (Time > 2200 AND Time < 2359)'''\n",
        "pb_weather_filtered_df = pd.read_sql(pb_sql_filter, conn)\n",
        "pb_weather_filtered_df.to_sql('pb_weather_filtered', conn, if_exists='replace', index = False)\n",
        "\n",
        "pb_sql_join = '''SELECT * FROM pb_draw NATURAL JOIN pb_weather_filtered'''\n",
        "pb_join_df = pd.read_sql(pb_sql_join, conn)\n",
        "\n",
        "pb_join_df.to_sql('pb_join', conn, if_exists='replace', index = False)\n",
        "print(pb_join_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REFZ6a_BDZOF",
        "outputId": "245ea0e2-65c2-4f8c-8412-e1ba6ea9e15a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Date       game  num_1  num_2  num_3  num_4  num_5  pb    month  day_name  day_num  day_date draw_time            DATE_TIME DPTemp DBTemp Precip RHumid  Time\n",
            "0     20140315  Powerball     34      5     51      2     58   9  January  Thursday        3         1      2300  2014-03-15T22:53:00     50     57   0.00     78  2253\n",
            "1     20140315  Powerball     34      5     51      2     58   9  January  Thursday        3         1      2300  2014-03-15T23:53:00     50     57   0.00     78  2353\n",
            "2     20140319  Powerball     34     23     43     19      2  14  January  Thursday        3         1      2300  2014-03-19T22:53:00     50     55   0.00     83  2253\n",
            "3     20140319  Powerball     34     23     43     19      2  14  January  Thursday        3         1      2300  2014-03-19T23:53:00     50     54   0.00     87  2353\n",
            "4     20140322  Powerball     55     13     28     58     31  15  January  Thursday        3         1      2300  2014-03-22T22:53:00     54     63   0.00     73  2253\n",
            "...        ...        ...    ...    ...    ...    ...    ...  ..      ...       ...      ...       ...       ...                  ...    ...    ...    ...    ...   ...\n",
            "2523  20230306  Powerball     69     58     13     29      2   4  January  Thursday        3         1      2300  2023-03-06T23:53:00     66     69   0.00     90  2353\n",
            "2524  20230308  Powerball     43     69     26     27     61   4  January  Thursday        3         1      2300  2023-03-08T22:53:00     44     63   0.00     50  2253\n",
            "2525  20230308  Powerball     43     69     26     27     61   4  January  Thursday        3         1      2300  2023-03-08T23:53:00     46     62   0.00     56  2353\n",
            "2526  20230311  Powerball     33     58     11     43     20  24  January  Thursday        3         1      2300  2023-03-11T22:53:00     50     58   0.00     75  2253\n",
            "2527  20230311  Powerball     33     58     11     43     20  24  January  Thursday        3         1      2300  2023-03-11T23:53:00     50     56   0.00     81  2353\n",
            "\n",
            "[2528 rows x 19 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idrfC-EBeKQN"
      },
      "outputs": [],
      "source": [
        "#weather_df = weather_df.astype({\"HourlyRelativeHumidity\": float})\n",
        "weather_filter_df = mega_weather_df.query('DBTemp == 42 & RHumid == 73')\n",
        "#weather_df.dtypes\n",
        "#weather_filter_df\n",
        "weather_date_unique = weather_filter_df['Date'].unique()\n",
        "weather_date_unique_df = pd.DataFrame(weather_date_unique, columns=['date_time'])\n",
        "weather_date_unique_df['date_time'] = pd.to_datetime(weather_date_unique_df['date_time'])\n",
        "\n",
        "weather_date_unique_df['time_only'] = pd.to_datetime(weather_date_unique_df['date_time']).dt.time\n",
        "weather_date_unique_df['draw_date'] = pd.to_datetime(weather_date_unique_df['date_time']).dt.date\n",
        "weather_date_unique_df['draw_date'] = pd.to_datetime(weather_date_unique_df['draw_date'])\n",
        "weather_date_unique_df['draw_date'] = weather_date_unique_df['draw_date'].dt.strftime('%m/%d/%Y')\n",
        "\n",
        "\n",
        "\n",
        "dates_list = weather_date_unique_df['draw_date'].values.tolist()\n",
        "\n",
        "#with pd.option_context('display.max_rows', None,\n",
        "#                       'display.max_columns', None,\n",
        "#                       'display.precision', 3,\n",
        "#                       ):\n",
        "#    print(weather_date_unique_df)\n",
        "dates_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yj1afnV9eKQN"
      },
      "outputs": [],
      "source": [
        "arr = mega_draw_df.iloc[:, 2:7].values\n",
        "\n",
        "mega_draw_df['check'] = np.any(((arr[:, 1:] - arr[:, :-1]) == 1),axis=1).astype(int)\n",
        "with pd.option_context('display.max_rows', None,\n",
        "                       'display.max_columns', None,\n",
        "                       'display.precision', 3,\n",
        "                       ):\n",
        "    print(mega_draw_df)\n",
        "\n",
        "mega_draw_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rf1pdLpXeKQN"
      },
      "outputs": [],
      "source": [
        "counts_1 = mega_draw_df['num_1'].value_counts()\n",
        "counts_2 = mega_draw_df['num_2'].value_counts()\n",
        "counts_3 = mega_draw_df['num_3'].value_counts()\n",
        "counts_4 = mega_draw_df['num_4'].value_counts()\n",
        "counts_5 = mega_draw_df['num_5'].value_counts()\n",
        "counts_MB = mega_draw_df['MB'].value_counts()\n",
        "#counts_df.columns = ['num_1', 'counts_1']\n",
        "#with pd.option_context('display.max_rows', None,\n",
        "                       #'display.max_columns', None,\n",
        "                       #'display.precision', 3,\n",
        "                       #):\n",
        "    #print(counts_1, counts_2)\n",
        "counts_df = pd.concat([counts_1, counts_2, counts_3, counts_4, counts_5, counts_MB], axis=1)\n",
        "with pd.option_context('display.max_rows', None,\n",
        "                       'display.max_columns', None,\n",
        "                       'display.precision', 3,\n",
        "                       ):\n",
        "    print(counts_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIvpommOeKQN"
      },
      "outputs": [],
      "source": [
        "mega_draw_df[0:2][['num_1', 'num_5']] #Slice the dataframe by selected row indexes and a list of column names.\n",
        "mega_draw_df['num_3'][:4] #create a series from the first 4 rows (0 - 3) of the column string \"num_3\".\n",
        "dft['num_2' : 'num_5'] #Slice transposed dataframe with row name from 'num_2 up to and including 'num_5'.\n",
        "dft.loc['num_3', 2] #Row/Column based indexing. loc uses lables to slice.\n",
        "mega_draw_df.iloc[1:100, :] #Slice dataframe by rows 1 - 99 and all columns. iloc uses integers as index positions to slice.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-m5lx8RQeKQO"
      },
      "outputs": [],
      "source": [
        "mega_draw_df['draw_date'] = pd.to_datetime(mega_draw_df['draw_date'])\n",
        "date_df = mega_draw_df[mega_draw_df['draw_date'].dt.month == 12]\n",
        "\n",
        "counts_1 = date_df['num_1'].value_counts()\n",
        "counts_2 = date_df['num_2'].value_counts()\n",
        "counts_3 = date_df['num_3'].value_counts()\n",
        "counts_4 = date_df['num_4'].value_counts()\n",
        "counts_5 = date_df['num_5'].value_counts()\n",
        "counts_MB = date_df['MB'].value_counts()\n",
        "counts_df = pd.concat([counts_1, counts_2, counts_3, counts_4, counts_5, counts_MB], axis=1)\n",
        "\n",
        "with pd.option_context('display.max_rows', None,\n",
        "                       'display.max_columns', None,\n",
        "                       'display.precision', 3,\n",
        "                       ):\n",
        "    print(counts_df)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TWf27M7eKQO"
      },
      "outputs": [],
      "source": [
        "mega_draw_df['draw_date'].astype(str)\n",
        "df2 = mega_draw_df[mega_draw_df['draw_date'].isin(dates_list)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with pd.option_context('display.max_rows', None,\n",
        "                       'display.max_columns', None,\n",
        "                       'display.precision', 3,\n",
        "                       ):\n",
        "    print(df2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Q_TPCOkeKQO"
      },
      "outputs": [],
      "source": [
        "counts_1 = df2['num_1'].value_counts()\n",
        "counts_2 = df2['num_2'].value_counts()\n",
        "counts_3 = df2['num_3'].value_counts()\n",
        "counts_4 = df2['num_4'].value_counts()\n",
        "counts_5 = df2['num_5'].value_counts()\n",
        "counts_MB = df2['MB'].value_counts()\n",
        "counts_MB_df= pd.DataFrame(counts_MB)\n",
        "sorted_MB = counts_MB_df.sort_values('MB', ascending=False)\n",
        "counts_df = pd.concat([counts_1, counts_2, counts_3, counts_4, counts_5], axis=1)\n",
        "counts_df['totals'] = counts_df.sum(axis=1, skipna=True)\n",
        "sorted_df = counts_df.sort_values('totals', ascending=False)\n",
        "\n",
        "with pd.option_context('display.max_rows', None,\n",
        "                       'display.max_columns', None,\n",
        "                       'display.precision', 3,\n",
        "                       ):\n",
        "    print(sorted_df)\n",
        "    print(sorted_MB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flLJ48T8eKQO"
      },
      "outputs": [],
      "source": [
        "draw_list=(sorted_df.index.values)\n",
        "draw_list_MB=(sorted_MB.index.values)\n",
        "print(draw_list)\n",
        "print(draw_list_MB)\n",
        "type(draw_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0XLuXnKeKQO"
      },
      "outputs": [],
      "source": [
        "draw_list = list(draw_list)\n",
        "new_list1 = random.sample(draw_list, 5)\n",
        "new_list1 = sorted(new_list1)\n",
        "draw_list_MB = list(draw_list_MB)\n",
        "new_list_MB = random.sample(draw_list_MB, 1)\n",
        "#sorted([str(x) for x in new_list1])\n",
        "print(new_list1 + new_list_MB)\n",
        "type(new_list1[1])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}